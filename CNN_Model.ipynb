{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5380830,"sourceType":"datasetVersion","datasetId":3120670}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Package Setup","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv3D, BatchNormalization, MaxPooling3D, Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-10T13:50:31.745023Z","iopub.execute_input":"2024-09-10T13:50:31.746170Z","iopub.status.idle":"2024-09-10T13:50:35.466297Z","shell.execute_reply.started":"2024-09-10T13:50:31.746112Z","shell.execute_reply":"2024-09-10T13:50:35.463890Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Constants\nIMG_SIZE = 256\nFRAME_COUNT = 10","metadata":{"execution":{"iopub.status.busy":"2024-09-10T13:50:35.467332Z","iopub.status.idle":"2024-09-10T13:50:35.467769Z","shell.execute_reply.started":"2024-09-10T13:50:35.467548Z","shell.execute_reply":"2024-09-10T13:50:35.467569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Frames and Dataset Pre-processing","metadata":{}},{"cell_type":"code","source":"# Function to preprocess individual frames\ndef preprocess_frame(frame):\n    frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))  # Resize to IMG_SIZE x IMG_SIZE\n    frame = frame.astype('float32') / 255.0  # Normalize pixel values\n    return frame\n\n# Function to extract and preprocess frames from a video\ndef extract_frames_from_video(video_path, frame_count=FRAME_COUNT):\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    \n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        frame = preprocess_frame(frame)\n        frames.append(frame)\n\n        # Stop once we have enough frames\n        if len(frames) == frame_count:\n            break\n\n    cap.release()\n    \n    # If fewer than frame_count frames, pad with the last frame\n    while len(frames) < frame_count:\n        frames.append(frames[-1])\n    \n    return np.array(frames)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T13:50:35.469586Z","iopub.status.idle":"2024-09-10T13:50:35.470092Z","shell.execute_reply.started":"2024-09-10T13:50:35.469874Z","shell.execute_reply":"2024-09-10T13:50:35.469898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Dataset","metadata":{}},{"cell_type":"code","source":"# Paths to real and fake video datasets\nreal_videos_dir = '/kaggle/input/celeb-df-v2/Celeb-real'\nfake_videos_dir = '/kaggle/input/celeb-df-v2/Celeb-synthesis'","metadata":{"execution":{"iopub.status.busy":"2024-09-10T13:50:35.471265Z","iopub.status.idle":"2024-09-10T13:50:35.471659Z","shell.execute_reply.started":"2024-09-10T13:50:35.471462Z","shell.execute_reply":"2024-09-10T13:50:35.471482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to load dataset\ndef load_dataset(data_dir, label, frame_count=FRAME_COUNT):\n    data = []\n    labels = []\n    \n    for video_file in os.listdir(data_dir):\n        video_path = os.path.join(data_dir, video_file)\n        frames = extract_frames_from_video(video_path, frame_count)\n        data.append(frames)\n        labels.append(label)\n    \n    return np.array(data), np.array(labels)\n\n# Load real and fake video datasets\nreal_videos, real_labels = load_dataset(real_videos_dir, label=0)\nfake_videos, fake_labels = load_dataset(fake_videos_dir, label=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T13:50:35.473232Z","iopub.status.idle":"2024-09-10T13:50:35.473652Z","shell.execute_reply.started":"2024-09-10T13:50:35.473443Z","shell.execute_reply":"2024-09-10T13:50:35.473465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combine and Split Dataset","metadata":{}},{"cell_type":"code","source":"# Combine real and fake datasets\nvideos = np.concatenate([real_videos, fake_videos], axis=0)\nlabels = np.concatenate([real_labels, fake_labels], axis=0)\n\n# Split into training, validation, and testing sets\ntrain_videos, test_videos, train_labels, test_labels = train_test_split(videos, labels, test_size=0.2, random_state=42)\ntrain_videos, val_videos, train_labels, val_labels = train_test_split(train_videos, train_labels, test_size=0.2, random_state=42)\n\n# Create TensorFlow datasets for batch processing\ntrain_data = tf.data.Dataset.from_tensor_slices((train_videos, train_labels)).batch(16)\nvalidation_data = tf.data.Dataset.from_tensor_slices((val_videos, val_labels)).batch(16)\ntest_data = tf.data.Dataset.from_tensor_slices((test_videos, test_labels)).batch(16)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T13:50:35.474609Z","iopub.status.idle":"2024-09-10T13:50:35.475071Z","shell.execute_reply.started":"2024-09-10T13:50:35.474838Z","shell.execute_reply":"2024-09-10T13:50:35.474868Z"},"trusted":true},"execution_count":null,"outputs":[]}]}